{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "googlenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKw9krGb4bgTNXb13npulK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adzanlr/Machine-Learning-Week-12/blob/main/googlenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "metadata": {
        "id": "pTYs1JPpilK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "nwqAY2wHh8pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the data directory\n",
        "data_dir = '../input/labelledrice/Labelled/'"
      ],
      "metadata": {
        "id": "ns4HdkuMh8sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "images = glob(os.path.join(data_dir, '*/*.jpg'))\n",
        "tot_images = len(images)\n",
        "print('Total images:', tot_images)"
      ],
      "metadata": {
        "id": "0Qy5a-rRh_wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_images = 3355\n",
        "im_cnt = []\n",
        "class_names = []\n",
        "print('{:18s}'.format('Class'), end='')\n",
        "print('Count')\n",
        "print('-' * 24)\n",
        "for folder in os.listdir(os.path.join(data_dir)):\n",
        "    folder_num = len(os.listdir(os.path.join(data_dir, folder)))\n",
        "    im_cnt.append(folder_num)\n",
        "    class_names.append(folder)\n",
        "    print('{:20s}'.format(folder), end=' ')\n",
        "    print(folder_num)\n",
        "    if (folder_num < tot_images):\n",
        "        tot_images = folder_num\n",
        "        folder_num = folder\n",
        "        \n",
        "num_classes = len(class_names)\n",
        "print('Total number of classes: {}'.format(num_classes))"
      ],
      "metadata": {
        "id": "KRWMGyBjh_y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class             Count\n",
        "------------------------\n",
        "LeafBlast            779\n",
        "Hispa                565\n",
        "BrownSpot            523\n",
        "Healthy              1488\n",
        "Total number of classes: 4"
      ],
      "metadata": {
        "id": "QxIcfsnOiDS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for the training and validation sets\n",
        "data_transforms ={\n",
        "    \"train_transforms\": transforms.Compose([transforms.RandomRotation(30),\n",
        "                                           transforms.RandomResizedCrop(224), \n",
        "                                           transforms.RandomHorizontalFlip(), \n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                [0.229, 0.224, 0.225])]),\n",
        "   \"valid_transforms\": transforms.Compose([transforms.Resize(225),\n",
        "                                           transforms.CenterCrop(224),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                [0.229, 0.224, 0.225])]), \n",
        "    \"test_transforms\": transforms.Compose([transforms.Resize(225),\n",
        "                                           transforms.CenterCrop(224),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                [0.229, 0.224, 0.225])])\n",
        "}"
      ],
      "metadata": {
        "id": "k5G8p_vUh_07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, validation and test\n",
        "train_data = 0.8\n",
        "valid_data = 0.1\n",
        "test_data = 0.1\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])#loading dataset\n",
        "valid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\n",
        "test_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"test_transforms\"])\n",
        "\n",
        "# Obtain training indices that will be used for validation and test\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "# np.random.shuffle(indices)\n",
        "train_count = int(0.8*num_train)\n",
        "valid_count = int(0.1*num_train)\n",
        "test_count = num_train - train_count - valid_count\n",
        "train_idx = indices[:train_count]\n",
        "valid_idx = indices[train_count:train_count+valid_count]\n",
        "test_idx = indices[train_count+valid_count:]\n",
        "\n",
        "print(len(train_idx), len(valid_idx), len(test_idx))\n",
        "print(\"Training\", train_count, np.sum(len(train_idx)/num_train))\n",
        "print(\"Validation\", valid_count, np.sum(len(valid_idx)/num_train))\n",
        "print(\"Test\", test_count, np.sum(len(test_idx)/num_train))"
      ],
      "metadata": {
        "id": "IABVOiB7h_3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom sampler for the dataset loader avoiding recreating the dataset (just creating a new loader for each different sampling)\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)"
      ],
      "metadata": {
        "id": "DH2aul9eiL2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataloaders using the image datasets. Dataloader is used to load our data in batches\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size = 32, sampler = test_sampler)"
      ],
      "metadata": {
        "id": "WOHGDIdGiL5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['LeafBlast', 'BrownSpot', 'Healthy', 'Hispa']"
      ],
      "metadata": {
        "id": "htYdF1vziNx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 #unnormalize\n",
        "    plt.imshow(np.transpose(img, (1,2,0))) #convert tensor image type to numpy image type for visualization"
      ],
      "metadata": {
        "id": "NBg9JPOFiN2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize some sample data\n",
        "#Obtain one batch of training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() #convert images to numpy for display\n",
        "\n",
        "#Plot the images in the batch, along with corresponding labels\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    #ax.set_title(str(labels[idx].item()))\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "metadata": {
        "id": "9BMmlK-ciSF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model architecture\n",
        "# Load the pretrained model from pytorch's library and stored it in model_transfer\n",
        "model_transfer = models.googlenet(pretrained=True)\n",
        "\n",
        "# Check if GPU is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()"
      ],
      "metadata": {
        "id": "kIoyJMYaiU4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the model to see all the layers\n",
        "print(model_transfer)"
      ],
      "metadata": {
        "id": "5AvdQYwSiXhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogLeNet(\n",
        "  (conv1): BasicConv2d(\n",
        "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  )\n",
        "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "  (conv2): BasicConv2d(\n",
        "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  )\n",
        "  (conv3): BasicConv2d(\n",
        "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  )\n",
        "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "  (inception3a): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception3b): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "  (inception4a): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception4b): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception4c): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception4d): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception4e): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "  (inception5a): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (inception5b): Inception(\n",
        "    (branch1): BasicConv2d(\n",
        "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "    )\n",
        "    (branch2): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch3): Sequential(\n",
        "      (0): BasicConv2d(\n",
        "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "    (branch4): Sequential(\n",
        "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
        "      (1): BasicConv2d(\n",
        "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
        "      )\n",
        "    )\n",
        "  )\n",
        "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "  (dropout): Dropout(p=0.2, inplace=False)\n",
        "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "gDHG4EdVizHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model that got the best validation accuracy\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ],
      "metadata": {
        "id": "mcDAyzUaiac6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model_transfer.eval() #set model into evaluation/testing mode. It turns of drop off layer\n",
        "    #Iterating over test data\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to \n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "metadata": {
        "id": "OO45HQitiddk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain one batch of test images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images.numpy\n",
        "\n",
        "#Move model inputs to cuda, if GPU available\n",
        "if use_cuda:\n",
        "    images = images.cuda()\n",
        "    \n",
        "#Get sample outputs\n",
        "output= model_transfer(images)\n",
        "\n",
        "#Convert output probabilities to predicted class\n",
        "_,preds_tensor = torch.max(output,1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "#Plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(30,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images.cpu()[idx], (1,2,0)))\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]],classes[labels[idx]]),\n",
        "                color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "metadata": {
        "id": "xHXRIGaMifhk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}