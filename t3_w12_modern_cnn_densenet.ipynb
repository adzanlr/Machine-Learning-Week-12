{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t3_w12_modern_cnn_densenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMiIstoSTwbrQfggOjVUJF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adzanlr/Machine-Learning-Week-12/blob/main/t3_w12_modern_cnn_densenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modern CNN - AlexNet\n",
        "\n",
        "theory : https://d2l.ai/chapter_convolutional-modern/densenet.html# Source : https://github.com/d2l-ai/d2l-en/blob/master/chapter_convolutional-modern/densenet.md"
      ],
      "metadata": {
        "id": "dSKKHmKxD7E8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlJ2W1CHD3eE"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==0.17.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting d2l==0.17.0\n",
        "  Downloading d2l-0.17.0-py3-none-any.whl (83 kB)\n",
        "     |████████████████████████████████| 83 kB 849 kB/s \n",
        "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.0) (1.0.0)\n",
        "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.0) (2.23.0)\n",
        "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.0) (1.1.5)\n",
        "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.0) (3.2.2)\n",
        "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.17.0) (1.19.5)\n",
        "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (5.2.2)\n",
        "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (5.6.1)\n",
        "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (7.6.5)\n",
        "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (5.3.1)\n",
        "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (4.10.1)\n",
        "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.17.0) (5.2.0)\n",
        "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.17.0) (5.5.0)\n",
        "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.17.0) (5.1.1)\n",
        "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.17.0) (5.1.1)\n",
        "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.17.0) (5.3.5)\n",
        "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (0.8.1)\n",
        "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (57.4.0)\n",
        "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (0.7.5)\n",
        "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (4.8.0)\n",
        "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (2.6.1)\n",
        "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (1.0.18)\n",
        "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (4.4.2)\n",
        "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (1.15.0)\n",
        "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.17.0) (0.2.5)\n",
        "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.17.0) (5.1.3)\n",
        "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.17.0) (1.0.2)\n",
        "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.17.0) (0.2.0)\n",
        "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.17.0) (3.5.2)\n",
        "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (4.9.1)\n",
        "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (4.3.3)\n",
        "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (4.10.0)\n",
        "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (0.18.0)\n",
        "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (5.4.0)\n",
        "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (3.10.0.2)\n",
        "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (21.4.0)\n",
        "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.17.0) (3.7.0)\n",
        "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.17.0) (2.11.3)\n",
        "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.17.0) (1.8.0)\n",
        "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.17.0) (0.12.1)\n",
        "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.17.0) (22.3.0)\n",
        "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.17.0) (2.8.2)\n",
        "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.17.0) (0.7.0)\n",
        "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==0.17.0) (2.0.1)\n",
        "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.17.0) (0.11.0)\n",
        "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.17.0) (3.0.6)\n",
        "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.17.0) (1.3.2)\n",
        "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (0.5.0)\n",
        "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (4.1.0)\n",
        "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (0.3)\n",
        "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (0.8.4)\n",
        "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (1.5.0)\n",
        "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.17.0) (0.7.1)\n",
        "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.17.0) (0.5.1)\n",
        "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.17.0) (21.3)\n",
        "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.17.0) (2018.9)\n",
        "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.17.0) (2.0.0)\n",
        "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.17.0) (2.10)\n",
        "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.17.0) (3.0.4)\n",
        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.17.0) (2021.10.8)\n",
        "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.17.0) (1.24.3)\n",
        "Installing collected packages: d2l\n",
        "Successfully installed d2l-0.17.0\n",
        "As shown in Fig. 7.7.1, the key difference between ResNet and DenseNet is that in the latter case outputs are concatenated (denoted by [,] ) rather than added.\n",
        "\n",
        "As a result, we perform a mapping from x to its values after applying an increasingly complex sequence of functions:\n",
        "\n",
        "x→[x,f1(x),f2([x,f1(x)]),f3([x,f1(x),f2([x,f1(x)])]),…].\n",
        "\n",
        "In the end, all these functions are combined in MLP to reduce the number of features again. In terms of implementation this is quite simple: rather than adding terms, we concatenate them. The name DenseNet arises from the fact that the dependency graph between variables becomes quite dense. The last layer of such a chain is densely connected to all previous layers\n",
        "\n",
        "7.7.2. Dense Blocks\n",
        "\n",
        "DenseNet uses the modified “batch normalization, activation, and convolution” structure of ResNet (see the exercise in Section 7.6). First, we implement this convolution block structure."
      ],
      "metadata": {
        "id": "uVkSb-roEAHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def conv_block(input_channels, num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
        "        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))"
      ],
      "metadata": {
        "id": "gscjm9R5D95S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, input_channels, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block(\n",
        "                num_channels * i + input_channels, num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate the input and output of each block on the channel\n",
        "            # dimension\n",
        "            X = torch.cat((X, Y), dim=1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "FWD70QAnECy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following example, we define a DenseBlock instance with 2 convolution blocks of 10 output channels.\n",
        "\n",
        "When using an input with 3 channels, we will get an output with 3+2×10=23 channels. The number of convolution block channels controls the growth in the number of output channels relative to the number of input channels. This is also referred to as the growth rate."
      ],
      "metadata": {
        "id": "K0LcFiW8ED65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blk = DenseBlock(2, 3, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "MR_nQ-NHEFAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([4, 23, 8, 8])\n",
        "7.7.3. Transition Layers\n",
        "\n",
        "Since each dense block will increase the number of channels, adding too many of them will lead to an excessively complex model. A transition layer is used to control the complexity of the model. It reduces the number of channels by using the 1×1 convolutional layer and halves the height and width of the average pooling layer with a stride of 2, further reducing the complexity of the model."
      ],
      "metadata": {
        "id": "TNwhL29DEGLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_block(input_channels, num_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
        "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2))"
      ],
      "metadata": {
        "id": "TCZiApCoEHRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply a transition layer with 10 channels to the output of the dense block in the previous example. This reduces the number of output channels to 10, and halves the height and width."
      ],
      "metadata": {
        "id": "BVbFtaz2EIOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blk = transition_block(23, 10)\n",
        "blk(Y).shape"
      ],
      "metadata": {
        "id": "6QXsapw8EIep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([4, 10, 4, 4])\n",
        "7.7.4. DenseNet Model\n",
        "\n",
        "Next, we will construct a DenseNet model. DenseNet first uses the same single convolutional layer and maximum pooling layer as in ResNet."
      ],
      "metadata": {
        "id": "1CPjfZAXEJUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = nn.Sequential(\n",
        "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "    nn.BatchNorm2d(64), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "IKfCCb4MEKdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, similar to the four modules made up of residual blocks that ResNet uses, DenseNet uses four dense blocks. Similar to ResNet, we can set the number of convolutional layers used in each dense block.\n",
        "\n",
        "Furthermore, we set the number of channels (i.e., growth rate) for the convolutional layers in the dense block to 32, so 128 channels will be added to each dense block.\n",
        "\n",
        "In ResNet, the height and width are reduced between each module by a residual block with a stride of 2. Here, we use the transition layer to halve the height and width and halve the number of channels."
      ],
      "metadata": {
        "id": "-BVR8tkPELnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `num_channels`: the current number of channels\n",
        "num_channels, growth_rate = 64, 32\n",
        "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
        "blks = []\n",
        "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
        "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
        "    # This is the number of output channels in the previous dense block\n",
        "    num_channels += num_convs * growth_rate\n",
        "    # A transition layer that halves the number of channels is added between\n",
        "    # the dense blocks\n",
        "    if i != len(num_convs_in_dense_blocks) - 1:\n",
        "        blks.append(transition_block(num_channels, num_channels // 2))\n",
        "        num_channels = num_channels // 2"
      ],
      "metadata": {
        "id": "6F1KGrqFEM-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to ResNet, a global pooling layer and a fully-connected layer are connected at the end to produce the output."
      ],
      "metadata": {
        "id": "cIkvBAxREO-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    b1, *blks,\n",
        "    nn.BatchNorm2d(num_channels), \n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveMaxPool2d((1, 1)),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(num_channels, 10))"
      ],
      "metadata": {
        "id": "kGaYNAREEQfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.7.5. Training\n",
        "\n",
        "Since we are using a deeper network here, in this section, we will reduce the input height and width of the Fashion MNIST data from 224 to 96 to simplify the computation."
      ],
      "metadata": {
        "id": "Zrd4uC4QERzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, batch_size = 0.1, 10, 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "metadata": {
        "id": "Hi8JoCcBESxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss 0.152, train acc 0.944, test acc 0.885\n",
        "1628.7 examples/sec on cuda:0\n",
        "7.7.6. Summary\n",
        "\n",
        "In terms of cross-layer connections, unlike ResNet, where inputs and outputs are added together, DenseNet concatenates inputs and outputs on the channel dimension.\n",
        "\n",
        "The main components that compose DenseNet are dense blocks and transition layers.\n",
        "\n",
        "We need to keep the dimensionality under control when composing the network by adding transition layers that shrink the number of channels again."
      ],
      "metadata": {
        "id": "V1tHujRlEUqx"
      }
    }
  ]
}